{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob as g\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ensemble :\n",
    "    \n",
    "    def __init__(self, data) :\n",
    "        \n",
    "        self.data=data \n",
    "        np.random.shuffle(self.data)\n",
    "        self.x=data[:, 0:22500]\n",
    "        self.y=data[:, 22500]\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def create_model_obj(self) :\n",
    "        \n",
    "        self.clf1 = DecisionTreeClassifier(max_depth=10)\n",
    "        self.clf2 = KNeighborsClassifier(n_neighbors=11)\n",
    "        self.clf3 = SVC(gamma='scale', kernel='rbf', probability=True)\n",
    "        self.clf4 = GaussianNB()\n",
    "        self.clf5 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "        self.clf6 = LGBMClassifier(boosting_type='dart', objective='binary', \\\n",
    "                     learning_rate=0.01, num_leaves=240, subsample_for_bin=5000, \\\n",
    "                     class_weight={0:0.6, 1:0.4})\n",
    "        self.clf7 = XGBClassifier(max_depth=100, learning_rate=0.01, objective='binary:logistic',\\\n",
    "                                 n_jobs=10, gamma=0.1, subsample=0.6)\n",
    "        \n",
    "        self.eclf = VotingClassifier(estimators=[('dt', self.clf1), ('knn', self.clf2), \\\n",
    "                                                 ('svc', self.clf3), ('nb', self.clf4), \\\n",
    "                                                 ('rf', self.clf5), ('lgb', self.clf6), ('xgb', self.clf7)], \\\n",
    "                                     voting='soft', weights=[2, 1, 2, 1, 2, 4, 3])\n",
    "        \n",
    "        return [self.clf1, self.clf2, self.clf3, self.clf4, self.clf5, self.clf6, self.clf7, self.eclf]\n",
    "    \n",
    "    def train_models(self):\n",
    "        \n",
    "        self.model_objs=self.create_model_obj()\n",
    "        for i in range(len(self.model_objs)):\n",
    "            self.model_objs[i]=self.model_objs[i].fit(self.x, self.y)\n",
    "        \n",
    "        return self.model_objs\n",
    "    \n",
    "    def cross_validation(self):\n",
    "        \n",
    "        self.clfs=self.train_models()\n",
    "        self.model_names=['dt', 'knn', 'svc', 'nb', 'rf', 'lgb', 'xgb', 'ens']\n",
    "        \n",
    "        for clf, label in zip(self.clfs, self.model_names):\n",
    "            self.scores=cross_val_score(clf, self.x, self.y, cv=5, scoring='accuracy')\n",
    "            print('Accuracy : %0.2f (+/- %0.2f) [%s]' % (self.scores.mean(), self.scores.std(), label))\n",
    "        \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    data=np.loadtxt('34552_sci_OK_data(without noise).csv', delimiter=',', dtype=np.float32)\n",
    "    e=ensemble(data)\n",
    "    e.cross_validation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
